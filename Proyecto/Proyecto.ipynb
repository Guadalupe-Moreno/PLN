{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto_APIT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7jevSdAJ8XK"
      },
      "source": [
        "### **Proyecto: Modelo de lenguaje neuronal basado en la arquitectura de Bengio (2003)**\r\n",
        "\r\n",
        "*   Aquino Santiago Rogelio Gerardo\r\n",
        "*   Moreno Madrid Maria Guadalupe\r\n",
        "*   Ramírez Ancona Simón Eduardo\r\n",
        "*   Ruiz Pérez Ariel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtiFkpgzJ1J9"
      },
      "source": [
        "### **Objetivo:**\r\n",
        "A partir del corpus **corpusML.txt** realizar un modelo del lenguaje neuronal con base en la arquitectura propuesta por Bengio (2003)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj1Z6E69HHAX"
      },
      "source": [
        "### **Introducion:**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imGiQvWwbuf2"
      },
      "source": [
        "Los modelos del lenguajes son una herramienta esencial en el PLN. Éstos se utilizan en múltiples aplicaciones. Su objetivo es estimar probabilidades de cadenas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsP2aK_VNNcC"
      },
      "source": [
        "![Picture1.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D67pm7myNUfi"
      },
      "source": [
        "Aproximan estas probabilidades por medio de asumir la propiedad de Markov (n-gramas):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaZ2r3gBNckB"
      },
      "source": [
        "![Picture2.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh6gnROpOPTo"
      },
      "source": [
        "Un modelo (estadístico) del lenguaje es µ = (Σ, P), tal que Σ es vocabulario y P medida de probabilidad sobre $Σ^*$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3TXsbaVO1V8"
      },
      "source": [
        "Se busca estimar un modelo µ = (Σ, A, Π)tal que Σ es el vocabulario, A son probabilidades de transición:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2U1QieuP1b0"
      },
      "source": [
        "![Picture3.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQEAAAAtCAMAAACZKy42AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAABgUExURQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPpP6I0AAAAfdFJOUwAQEyAiLzA8QEpQWGBncHaAhY+Wn6ivuL/Lz9zf7u9EvwJ9AAAACXBIWXMAABcRAAAXEQHKJvM/AAAEr0lEQVRoQ+2ZYXObMAyGEw9CU5oSSl1CiKP//y8nWzJ2WozFbr3ddTxfELkErNeSJTu7jY2Njb/D/nxhK8n57RdbP5HD9f66ZzvF4QNe2fx5HO5Xyfye4Y2tn8b+dpcF+Ac8s/XDeIcXtjKIpZql0g1bs1TQszXP0BVsyVAGKjZzHODKVpYXeGdrNUqbRrE9S06BQpuaTREtiBU4w5mtLHu4s7UWNZiSzQQ5BXa7GhaD6JECxDGwv4E8tMUJ8xkNGQEECuC0HtnK02st/fazPAl2u1f4YGsdR+jYSiJQQI3jYiJFVKZopCFzXpPbhz9MgwGyy5hAgV0DJ7ZyjA1+WajAQ6Oj2hGMrsdUyO5BlDKVBnPcqc5A6+5LGNy1AgB7Ve6+ATD2jiAFeqBxU8Dj1x9cLmBkK8MJg+VRAfvqiFjtW1TkS4PrrRogPWN3eGILQRdiphdWQ3GEvuwL1ZMH02BOADaOcTj2ro0HQgqokUTr3S/U5/V8zMeSRaH++NI48xYUgOATvt5OfrOg9DWOmJQCSAXDgL6iEPaunxwhl7BS2ZsGovrGWdCQEPy0zyPp41+kae0z6El5MK4PbOLA3GsfxXvkItwcHMlVnuxQmMgaKcp07B8rcHKXGtwYys8Oy3K7cBNJT8rzK2Q2Cu9irOXk63zIDc4Nx0XYPLSkYkWZTjpYXDTUprWXgvxz9qQAXUaawM5JVIQZWZqcAC4mjtUK1Lxe9Vy7Rz9F0aOkCvRUjHkeYgVwEvumsV63/nXuMimAt5VR9q6w6WzHNUWCKLIrmrlKuGxGWdDSIoSh4G5nkSrAz+jokeGJNoxro2xZK2juPayA+y7WMhs83Rd3RQrgry2cgUx6JYwUoPV3+S3XuClMr4S4ELqroXCiCmBBBdRYuwa3p0rpiRQ44eSNYLsa90mEJAsaTl6pAlF94wpkyJUOuKvErAojiWvnggIc/TW/KayENegGxamgsSUbwWdQjHsFRqhs8PegRrccFcBqWgQroTL8dfRZ1kGG+kaloO94SIN/wBD1LbKOCLcB1h018naIVwUEk9OgGvbCH7W86ngFehisgRf25MhtlUVQDbUXTPspzPE2ZTYOSxW6xipdaBxl7xcSQ0OzHAByp2kO7CxLbIz8fjZMHU4MrwzeLc2xGhRwwd/QBakir7MdEfZgANpa1rBi53kJm52TAY0DNzDYd/qUK6LIE26jsHvtUITpTMN3xQiq7C62X3KMrK9XgHv/0C35vEbEXfEqUnv+yrfkxyiY3mWl4EjTEEjPnfLB4BX4Qh+SUL4zWsVlfs/fcH5ioobR30IDuYTvqSbSu+Ojn+ukAkFNZYxsbVtJ4ujL52c8B8/C44GwD/AkT0gmoVMKlCEJ15yQrGL+kAhbtc75EY3sEu8MF/h6RJc8JeOOMK0AFs6SoqCOisLf5Qnm/jCqYXSK4wjcPSI9KMUFn34bobQ5zYXw5HdKAdysd/aHhf6eRcCx+FfIaQq9w/0qKoUJKj3jQSme17Wn5et4W5BgWgaeZP8srWNaBv41h1uq05mOqM/5vxbXU0bd1r9mvsqdgJpzZP8N/oNpv6W8bWxsbGxsbGxs/E/sdr8BEmplfP5rSMgAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fybUSVXsQB5k"
      },
      "source": [
        "Y Π son probabilidades iniciales:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ogx1UeRPGh"
      },
      "source": [
        "![Picture4.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAV4AAAAyCAMAAAAjtEO9AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAzUExURQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKMFRskAAAAQdFJOUwATIi88SlhndoWWqLjL3O5QTd6UAAAACXBIWXMAABcRAAAXEQHKJvM/AAAGQklEQVR4Xu2Z2barKhBFgzG2KPX/X3tXNSDYxOSc3DHOA/NhR2OEYlWH7kelUqlUKpVKpVKpVCqVyj9Ot3R2VPl7OurtKNIF7+zwc9wS7OiKnl529Evm8L2tj2eY7eiMJw12dMmLEot9dU4Tjtch1dc2j7fieXra0YFFDJ3TCO20Eq1To2cNn82tnuwZ/sRpS7Chz7mRDEy0emElb1+d4+nE7jPN39PeTAMC2cGBhgIsDWRKOQ9tPf7o+TPgMgQ+d057H2oHhpt7/KWlkSWqNr4f6kKW/lAxbjj1UkFz7YCXXIKqkrJuoYUHaxbiJHJBVtCuMaFcEa4f+HWPCzfJeb8YIhvBv0+ei5FggR19xgeLfNFoR0abZrZoGnQQT1b6HRGabLdP1Y58Hsj3mbznLnjvC05Lqx0RvSszrRjXTEjMiC564pW9JXjsMSiopeJEpLOcaRnGUEUGDOWIrd/OLQQGmvC3k5gVPI9nom+4iWjcwo+yTB73LjTQrNyw0irTIB0cFq73ORFgIMrD6Vb/XvOMB97um7Qag6T4zGtEccvQa50sNeLsPu9Tx33S5GlBT2KRnuJNt+rqRBWOvSIxis7WYa2b2kEnXeWGZVubDNRvckdauDXdncsr/m3NVO/TQD1BXK7fPE8vS+s1vyEz/2AsfHgr7xR/gEzSA2D6ZZ6CBJhjHJuHCLNslm7hz7CvlSQvgixADY0tixo9waAyeTFC3tlcKS53NvxFUPKyn1m6ibwItrXwE9MHrc8ym3wK84x7EYpGyp6JwoIr6vdFc0W9P+rtZWrd9KuPO1sX5Wp5+CYvY7nVZ8Aujkb1/qqR2Yu8HZlOucVbZ3MD9CouvWzjIJb2mRGLCMTJxbIVuFlngQEf1N6FpDGK+9WZ7G6WyCJ6LkLhpl+xOJZQ7385RwcPPEmfVy4Lop1IG15/LPLGCqQNbtUgnsTiZHfsbIi7Utwt3CThp8wIKy8OrgyHbZnFne46brAtnhgW66Y09S6M/NHoKoMVxBScF3za2bTaAc/6SCGO2NK6q2cBG1gUjRVItG6D49MmyIrWWE1i+qEtyWeGhkAzS5HVBBYQ1XaEAN7FKOpLkNAYjuMdiHJITY11Uybyw8DrHGX0JgZbCs4LTjsb8sBIvkkVANuA1GGUvDE1dh+wbzCwrle6fWoFfH0dHjzppIonYmdD2593xtu82gszeb2mPwPH5WHCxXvQUQ7pidpkJAtiWspmJW5F2eguuAGaNtlawW29SZ0tTx3tpiC1pxTk8ugTi5KSr+dpN2a9OO4sVl5d2mNB3h5DroQYzuUAqbNx2089h0nz7uTNJYX023h5Z9TmnNOZqd4n3W2XiSjBb+NIkNdhmA7z+TIBrrZ3iVQ83m8x0sOAFKDU5wQN1JNUVqxlvsRB6dkExYZrgie3WubGxefPbFvbF2IIYC+Cv1MMHWzzNtv1mgBxs1d6pdEXmByjhETMQNw5YCpEVq8PhNhnygWs4qIgRj7sbEle3miXrrDAfuXlOMcTb8tQE3n8JC8s5BF5Q6xfLJYeGCjzE/eq7cHA5m3t4Rc7Ar7UBRFjlvc6uBYDHnU+c03RL9otuUqIeFsGF/FYUV6skJfAH6qRs4TUTfwbUtKX5fRAlFc3Q2gSboqmW/K3V/ejl0NK2xxl8soKBv3gL9Ri/qrw07N4ZuO3T+gM6gBIT/J+R07xuWzXwPYozTS5FHiatqOSFraStyegTF4ddBvbTLp9YE0Z44pyesDkbYLMwK9S0sA2x3BxPzobOj0t6vckL/cJ+YjjpKA7vI18pejVlrsmz7Yza2pvI5sRsmzX9hTbenteOIDOhoJPs1oQ5cVjj5hAi1nSqonQLJn2l1y2yPhKZz6PhxjcxuUrkGfUfetsP+X23ZdQhiMagx3t6NXE9+3qK9Diz4lz2BubA2MKS4a77ylmcdnZfsh4l8fCUmTOlFy+Q0OpCTeV9wumi9IaX6dv0bcjlQOhKWI5IwX/4W3kT4ib7xtSORC6K5doKM1vNwPf0Z2P5eI/S1pq+1NjdjV9vVim9412gV1n+xH++Kh8Qlvu3ZorT9PQjvjxRaT8jk5eLzFuvaoOn9GXb77/bWbdEf7f1H/EVyqVSqVSqVQqlUqlUqlUKpU3PB7/Ad3dTIehrU6TAAAAAElFTkSuQmCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4-SR4HROwD"
      },
      "source": [
        "De esta forma, se pueden obtener las probabilidades de cadenas como:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCc6NfZbRmHO"
      },
      "source": [
        "![Picture5.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYsAAABgCAYAAADsFF5+AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAABDgSURBVHhe7Z3Lix3FF8c7v73GMVmJBEkiRGIY0ImCL4iLJGQREJS4cCEoaoy4UBl0EnDhM1E3gtERBRdBE8zChY+okEAiATNRElDcOCJBXGke+gfk158zfcaaTt9+33v7znw/0KlO99zuqjpV51SdevSyyzGREEIIkcP/klAIIYToiYyFEEKIQmQshBBCFCJjIYQQohAZCyGEEIXIWAghhChExkIIIUQhMhZCCCEKkbEQYoT57rvvoo0bN0bLli2Lpqen7Rrh2rVr7dq+ffvsmhBN0QpuIUaU3377LdqxY0d05MiRaOvWrdGKFSuiW2+9NVq1alX0+OOPmxE5ffp0pCou2kA9CyFGlNWrV0czMzNmJODUqVPRhg0bzFCAXxeiDdSzEGIRgMtpy5Yt1stwcEWNjY2ZQRGiKepZCDHiMG4B9913n4WAi2p2djbavHlzckWIZshYCDHinDx50sL169dbCLikALeUEG0gYyHEiHP06FEL77rrLgvh+PHjFt52220WCtEUGQshRhx6EYxXhOCGAgbBn3zyyejgwYP2fyHqImMhxAhz9uzZ6MKFCzZlNuTpp5+2wW0GucfHx6MHH3wwuSNEPTQbSgghRCHqWQghhChExkIIIUQhMhZCCCEKkbEQQghRiIyFEEKIQmQshOgQ7PHUlcO3ERECZCyE6BDs57R3715bIzEsdu7cGZ05c2bBinAhtM5CiA5Cq/7uu+9O/heZAZmcnEz+1x7p97z33nvzW5wLEaKehRAdhFb9mjVrkv8Njvvvvz85E2IhMhZCdBS26hgkuL70wSTRCxkLIYShHWpFHjIWQgghCpGxEEIIUYiMhRBCiEJkLIQQQhQiYyGEEKIQGQshhBCFyFgIIYQoZOjGgg/L80F5fSO4fTxfl+qGcKSb9O/bty+50n8OHjwYbdy40UJRnmHrga1bty7azRPb0gNDNRZUYt/S4NVXX7VQtMdLL70U3XLLLbb3z+7du5Ori5+///7bKsf27dst/Y888khyp//w3meffdYqKAqIuIh8pAf6S2t6gI0Eh8HOnTvZwPDyJ598klwR/eLMmTOXx8bGLm/ZsiW5snj566+/Lk9MTFh6SfewCOPBeR2QF3WEY+/evcnVdjlx4sT8O4ZRPrqiBzyvyY/FSlM9MJSexfT0dPTuu+/aDpfD6nYuJcbHx6MDBw5EX3/99aLvYezatSs6ffp0dOzYMUv3sGCPpUOHDtk5PQxxJdIDg6WxHkiMxsCYnZ016xZ3O5MrYlDs2LHDWk91W9y0kL0liAw5R569oLWYd79tvvjiC4sb8eoKsSK0OBFWZTH3LLqmB5ZCz8KpqwcG3rP48MMPowsXLkQvv/xyckUMiqeeesrC1157zcKq0EKmJQjIkPOJiQlrIaY5e/as+e1PnTqVXOk/L774ooXPPfechV2ALb9jpRi98MILyRUB0gPDo7YeSIxGKWhZ0sKhNcBPw5YIrTp8tFznfi+rRWuCv+nlxy1qTU1NTdk93hfiv+Go04rrJ11Kk8uuaoufeCM7b3kRhuniPLxHWQjLRxHEhx6Bl48wn9JlLqvsUN64z3t74XHlyGpBevkNn8/fhb+r0yur65cvKjdtEKavrLyaygqK9IDHiWMQsvK8Dt+Vfl4a3s31dJkjD/w3pLOL1NEDlYwFGepKy4VFhlJw/Lq7ArIyyTM/r1AiAE8ISjSNCzVdeVxwHKHAu0CX0lRXcSHPtDED5O5xDA/+vmxB9PwhjWGaOSdvPO1uVOlGp/EKms7DEDcoHFlp8XvpvA7LNHGqCnnN78n7Kni54MhLVxNIq78jr146bcjK35n3vkHLyvM6/bywfKef5+ngSOPpL5Onw6COHqjkhjpy5Mj8Jxf9Iyl0Ixk48evbtm0z1wRdzPS83pMnT1p47733WpgFz33sscfs/IcffrDQYRoigzNZeHzigty5bwd3KU033HCDhcePH7ewDMRx//79Jts0yD02Cvbd5riC2rVYQdgA8+rVq+3/RZDOX3/91dLoaeZZuL1iJTmf9meeecZCHzgOOXr0qIV33HGHhVlQTuPKa+c//fSThc6XX36ZnF3J1VdfbSGDsB6/Klx//fUWfvPNNxaOMm3IqoweGJas0oSfmP3ll1+Sszm++uqr5OxKli9fbuHDDz9sYdeoowdqj1mE88fT3+x1IXmhcH788cfkLB/P6DTffvttchZFv//+e3I2Bz5y6KoPtCtpcmXKIqiyIM+82SoYBYzJ+fPnaWLZgrS6M5G8XNHYeOCBBxY8J6z86YZI2bGRa665JjlbyOeff56cRdEff/yRnM3x888/W1h3LMQVKEZ1MVFXVmX1wDBklYU3gtKEhjBdn0gjjbyuzvKqowdqGQsKCdMTASXRi7SCvHjxooV5rT9Yv359craQPXv2WOsF0olkkDVLOPwdKzMZbB0mbaapDWgdVgW5k4/k57XXXmvneYUNo1GlMML3339vIemenJy08yyuuuqq5GwOFBa4Yu4Fi5PSEEcG610O586ds9B54403rOeU7imRPvKiymrtqvnRZerKqqweGLasnKwvCPIcGkdTU1P2/z///NNCII4YkqxGHp/KHfTncvOoogdqGQvvjuFuynI1eCuvl4IsS+ieoXWCcLJW4yIchPf2228nV/7D43LPPfdYOGzaSFMb1GnlDmI2lLsccGWl8Z4W1O25OO62gsOHD5vLI0t54fJARlktVe/CV/kcaahURp3FLqs0oafko48+ip5//vlMjwEzvagXWQ1X6t3mzZuTK8Onkh6YG7qoRmzVbXCEME388vlBn/SAEIM9XE8PImXhz3Di1sv8+7jOAJbDYA3P7jpdSFPeoFwexJP4uewIXZ4cnIf3mABRJ/7+TH9WiA8U8+w0Ho8ieK7HF7y8ct3vhYOyoYya4PHLSlcvwvxtIw5ZeJo5qsqrrqzyfhficRuErPLixDO5588mbdQF9Jvf8wk+YRwHBe8i/lXS7vnHUZZaPQu39DfffLOFIe6Dp7XRa4Dpn3/+Sc7K4S1X7+rS7XW3A61zWuB57rAuMuw08b6y4H56/fXXbfWnu3kImfAQVxL7Pz0m9p6hq09Ii6VO/L3nddNNN1kY8tlnn1n46KOPWpiF+9HLghsBtwXpue666+yau0nYswh/dZ6LpSr+jsVAU1lV1QODllUWlC9cx5Rt9NuqVavs+qVLlyykN008i9yhbUBPhfdR30KPRRWq6IFqzcsErCo/zbKeWPde92gFcK+MBQyfw/vC6XPeCsCy83du1UPCHk5W62YYNEkTvyEd/I3fI/Rnlm1V8Bz+3ltrZcmavuiQ1/SEvFwg5zrrEcLpkmlcnrwj3WOFvDIZEj7H5cA1h3vkjcclKx3eauZgimQZ/O+r4GWCo0qrsQpeHjiqlIkmsiqrBwYpK8/rrPLjzyDexDnUJ55/XPf6mJVmr6ccWferwnt5JnHz6cJVyojHu4rMKxuLsJCkM5bM4jqKIwsSw/0yFcyFh2DSCQrv5RkCz8SyFRo8jhwhVa9nUTdNVBCuUcj8t6TJjQbXyrwfPL69ZDRMvPxkpcUVDJUjC8+/PKPm+DvIN/IjJLyXV264V/Z9XjGp3FXwNHGk49kWHjeOdJnMo4msvAyWqZf+jn7LyvM6rdMglJ8bLid9r9c7qLse17Zwo+NxqFJGXAZV9EBlN1Q41/jjjz+2kK4Z3cAnnnjCBp/YEjcLH5RKrzXII1aUV7gzfH4297LmcTs+53rDhg0WdoWqaWISwczMzLxbj0Fj0pRe81IGn57blQH/kHBQFDcc0NVmoJA8iSt9z5lhnn/pOflFpN0WlF/nlVdeSc6uxAc2161bZ2EePr2zSwObTWkiqzp6AAYhqzyom+4Gc/zc72WtRQKvo3zrpC2q1Ps0dfRAZWPhswrIGAoHPuqVK1dGn376aRS3JMyP3SsRZGxsfc2/VuRb9srP/iVZM64AhdvrHvjshSYzINqkjTQxZZn0hBWR6W9xiyX5Xz6+MKwreRLicUPRvPXWW1a24habXYtbT7kKwRUH5bAI/9sPPvjAwjSU0V73HMbtiFuerByvM1000HVpIqsqemDQssrCDQLP8MWGaah/ve6BrzXJKgPMMiT/ig5/RhvU0gNJD6M0dKP4WZZ/sAx0e/h9ry5qm8QFzbqGiwXvbrr7CeIWjV2jq12E/x43QdfwbnoTecWV2Z5BnvSbsvlIukhTnXRRfnkPR5fcUG3IapB6gPcUycrzmvzoB+72qas383AZli0jdfVApZ4FrQBatnEhqT13mjnQ/J4ZBf2Glsti6vp7Tylcv+LrGMq42nyRkO862SV8gVcTefmalDfffNPCfuEtvE2bNlmYh++uypz8xUIbshqUHqgiq35C76aJ3myTunqgkrHw8YomLgy6grhh8PFlLeZqC/epZq0CHVV8ynLoMy272IgFSxhP3Abh77uCjzU0kRf+4ri1ZIsFQ5962/iWEkWLTnHTMuUYF0W/p3QOkjZkNSg9UFZW/YZGXRdcv030QCVjkd7rqS4MzDLmwYC4D461zb///puczRmOXoNtowQFzn24DgoJqHzMuc7KT9L/0EMPmdLK8yUPEzeETXnnnXcsnbQk+2UwfE49kN9M7khDLxzDBXmTMEaRtmQ1CD1QRlaDwNdQUS4YoygaqykLz/ENDdmPKu+5jfVA4o4qRehDrervysL9ePjb2/Yz41f18RX8oz7NbFTxKcvpsQmm6uE7xl8fjmUAaQ6nyHU5D4gjB2lp6p8nnZRPnkWetJ1uZMGze8UVPzz3KH9NynVXxyz879uQFXgZ7YceKJKV0+8xCx+j4T1tjVu4HLKOkLb0QOUB7rahcJAADtEu5ClKs18VoOuQbtKfNqL9BEOBkWhj4LarxqIfSA/0j7b0wDL+iQuKEKJj4K7AvwyxsejLuAcDwGwXAbGxsKnvQmRReZ2FEEKIpYeMhRBCiEJkLIQQQhQiYyGEEKIQGQshhBCFyFgIsYQJP0BU9RO4YmkhYyFERwk/ps/q3H4QbunOKuO2VhaLxYeMhRAdhPUPs7P/fUyfLaX7ocjff//95GyOw4cPJ2dCLETGQogOwV5f7F+0ffv25MoctPpvvPFG29+oDaPBhnJ8iCc0SMA+Tewx1s+NGMVoohXcQnQIPnJTRNOV1uHK8DxOnDjRyR2KxXCQsRBCCFGI3FBCCCEKkbEQouMwToF7ql/ffBCiDDIWQnScsl9DFKKfyFgI0XH279/Pd2fsa4hNYZYTs53Wrl1rvRUOviKp2U+iCA1wC7GEwDiMjY1Fx44di8bHx+e/Z7FmzZoFiwCFSKOehRAdxccqOHbv3p1cbc6BAwfMUABTY5mKm15vIUQaGQshOgruoampKTu/8847LWwKjoRt27Yl/xOiPDIWQnSY5cuXW7hu3ToLHVZ5e68j7+Dv8sANxQI9N0pC9EJjFkJ0GFZbM5bQj/EEBrU3bdpk4xUzMzPJVSGyUc9CiA5Dq39iYiL5X3uEhqLJ1iFi6SBjIURHwUUEKPU0TdxQaUOxYsWK5I4QvZEbSoiOMj09bbvAtrmhHzvW3n777TZ9VoZCVEE9CyE6yqVLl5KzuWm0RYPVZdi1a1d0/vz5KwwFYyPekxEiCxkLIToK6x/oAfBti3PnzkWTk5PJnXrgfjp06JB9G2PlypUL3FVltiwXSxu5oYQQQhSinoUQQohCZCyEEEIUImMhhBCiEBkLIYQQhchYCCGEKETGQgghRCEyFkIIIQqRsRBCCFFAFP0f75SQC2/IPNkAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MznXdtENwN9"
      },
      "source": [
        "Bengio (2003) propone estimar los modelos del lenguaje a partir de las redes neuronales.\r\n",
        "Sus objetivos son:\r\n",
        "\r\n",
        "1.   Asociar cada palabra en el vocabulario con un vector distribuido en $R^b$\r\n",
        "2.   Expresar la función de distribución conjunta de las secuencias de palabras por medio de estos vectores.\r\n",
        "3.   Aprender de manera simultánea los vectores distribuidos y los parámetros de la función de probabilidad.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la5hjTwIPB-J"
      },
      "source": [
        "### **Desarrollo:**\n",
        "\n",
        "0. __Lo primero será tener disponible el corpus.__\n",
        "\n",
        "Para esta parte subímos el archivo a github y luego clonamos el repositorio en la máquina virtual donde se ejecuta el notebook, en caso de que se elimine el archivo solo ejecutar la celda de abajo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdMM2kSlUqNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0a2a36-c793-4ad6-bbac-4ce0f0063b1c"
      },
      "source": [
        "!git clone https://github.com/MariachiAncona/corpus.git\n",
        "!mv /content/corpus/corpusML.txt /content/\n",
        "!head corpusML.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'corpus' already exists and is not an empty directory.\n",
            "mv: cannot stat '/content/corpus/corpusML.txt': No such file or directory\n",
            "Comencé a trabajar y me pegaron, me maltrataron con chicote \n",
            "Mis patrones me pegaron porque no me quería apurar, porque era flojo \n",
            "Por eso, me habían pegado \n",
            "Cuando me pegaban ya entonces me quitaba \n",
            "Pues entonces no quise trabajar \n",
            "Ya no quise estar, como me pegaban \n",
            "Después ya estuve nomás en mi casa \n",
            "Fui a juntar caca de caballo \n",
            "Fui a juntar caquitas de caballo \n",
            "Se me aventaron las culebras \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HrGCXRQUoK3"
      },
      "source": [
        "1. __Limpiar los textos y aplicar stemming a las palabras.__\n",
        "\n",
        "Esta sección se realizó a partir de algunos pasos del archivo en [este enlace](https://colab.research.google.com/drive/17p3ef9HyZ9N9rixGdr5yhLd_VGT0zpNk?usp=sharing) además de que se usaron algunas de las bibliotecas, por ejemplo nltk y regex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iQSiYGIbNF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac01e51-5196-4361-fc2c-6dd84a379c93"
      },
      "source": [
        "import nltk\n",
        "import regex as re\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg4xPQPN8Rxx"
      },
      "source": [
        "Una vez disponible el corpus se procede a abrir el archivo y separar en tokens para poder aplicar el algoritmo de stemming (también parte de nltk)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkuYGPv1O9wy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c433e262-475c-4a62-dbfc-9be270cfc5e5"
      },
      "source": [
        "#Abriendo el archivo\n",
        "try:\n",
        "  with open('corpusML.txt','r') as f:\n",
        "    corpus = []\n",
        "    raw = f.read()\n",
        "    for line in raw.split(\"\\n\"):\n",
        "      corpus.append(line)\n",
        "    print(\"Archivo abierto con éxito, tokenizado en variable corpus\")\n",
        "except:\n",
        "  print('Ejecutar la primera celda si no existe el archivo punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archivo abierto con éxito, tokenizado en variable corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pckApB19p28"
      },
      "source": [
        "Hasta este punto el corpus ha sido leído y tokenizado en una lista, lo siguiente es limpiar el corpus para eliminar signos de puntuación y símbolos innecesarios.\n",
        "También se separará en conjunto de oraciones para entrenamiento y para prueba, usando sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOTBSjVY8j35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad52d839-7d46-41e4-af56-eec9683224ea"
      },
      "source": [
        "#Limpiando el corpus de signos y símbolos\n",
        "sents = []\n",
        "for sent in corpus:\n",
        "  sents.append(str.lower(re.sub(r\"[^\\w]\", \" \", sent)))\n",
        "print(sents[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['comencé a trabajar y me pegaron  me maltrataron con chicote ', 'mis patrones me pegaron porque no me quería apurar  porque era flojo ', 'por eso  me habían pegado ', 'cuando me pegaban ya entonces me quitaba ', 'pues entonces no quise trabajar ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zXUopW-BhhS"
      },
      "source": [
        "Una vez limpio el corpus se aplica el algoritmo de stemming, en este caso el stemmer de porter genérico de nltk _PorterStemmer_ no ayudó mucho así que se usó un stemmer para el español, también proporcionado por nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHjdHm2JBeek",
        "outputId": "7c91517b-b8e3-47cd-b839-261eb9f62e71"
      },
      "source": [
        "#Importando un objeto stemmer de nltk.\n",
        "#Se usará un stemmer para español porque el resultado no es\n",
        "# muy bueno con porter, es casi la misma oración lo que \n",
        "#alterará las probabilidades.\n",
        "#['comencé', 'a', 'trabajar', 'y', 'me',\n",
        "# 'pegaron', 'me', 'maltrataron', 'con', 'chicot']\n",
        "\n",
        "#from nltk.stem import PorterStemmer\n",
        "#ps = PorterStemmer()\n",
        "\n",
        "#Aplicando el stemming a las palabras.\n",
        "\n",
        "from nltk.stem.snowball import SpanishStemmer\n",
        "\n",
        "ps = SpanishStemmer()\n",
        "types = []\n",
        "\n",
        "for sent in sents:\n",
        "  types.append([ps.stem(w) for w in sent.split(\" \") if w != \"\"])\n",
        "print(sents[:5])\n",
        "print(types[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['comencé a trabajar y me pegaron  me maltrataron con chicote ', 'mis patrones me pegaron porque no me quería apurar  porque era flojo ', 'por eso  me habían pegado ', 'cuando me pegaban ya entonces me quitaba ', 'pues entonces no quise trabajar ']\n",
            "[['comenc', 'a', 'trabaj', 'y', 'me', 'peg', 'me', 'maltrat', 'con', 'chicot'], ['mis', 'patron', 'me', 'peg', 'porqu', 'no', 'me', 'quer', 'apur', 'porqu', 'era', 'floj'], ['por', 'eso', 'me', 'hab', 'peg'], ['cuand', 'me', 'peg', 'ya', 'entonc', 'me', 'quit'], ['pues', 'entonc', 'no', 'quis', 'trabaj']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eyAj7DpPqsF"
      },
      "source": [
        "2. __Insertar símbolos de inicio y final de cadena.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnVLmkTlPv42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e83859-7395-4a5c-8906-0128b7f31b50"
      },
      "source": [
        "for t in types:\n",
        "  t.insert(0,\"<BOS>\")\n",
        "  t.append(\"<EOS>\")\n",
        "print(types[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['<BOS>', 'comenc', 'a', 'trabaj', 'y', 'me', 'peg', 'me', 'maltrat', 'con', 'chicot', '<EOS>'], ['<BOS>', 'mis', 'patron', 'me', 'peg', 'porqu', 'no', 'me', 'quer', 'apur', 'porqu', 'era', 'floj', '<EOS>'], ['<BOS>', 'por', 'eso', 'me', 'hab', 'peg', '<EOS>'], ['<BOS>', 'cuand', 'me', 'peg', 'ya', 'entonc', 'me', 'quit', '<EOS>'], ['<BOS>', 'pues', 'entonc', 'no', 'quis', 'trabaj', '<EOS>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhnlQVgJ1R0-"
      },
      "source": [
        "En esta misma sección se indexará el vocabulario y se agregarán etiquetas _\"\\<OOV\\>\"_ para los hápax del vocabulario. \n",
        "Una vez indexado el vocabulario las palabras de frecuencia 1 serán reemplazadas por la etiqueta mencionada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdZ0c-bw2YMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0435dd3-8927-49da-fd0b-57c02419b7e3"
      },
      "source": [
        "#Indexando el vocabulario\n",
        "from collections import Counter,defaultdict\n",
        "from itertools import chain\n",
        "\n",
        "#Aprovechando collections\n",
        "#Frecuencia de los tipos\n",
        "freq_words=Counter( chain(*[' '.join(sent).lower().split() for sent in types]))\n",
        "\n",
        "corpus_hapax = []\n",
        "\n",
        "#Recorre y reemplaza las palabras de frec 1\n",
        "for sent in types:\n",
        "  sent_hapax =[]\n",
        "  for w in sent:\n",
        "    if freq_words[w.lower()] == 1:\n",
        "      sent_hapax.append('<oov>')\n",
        "    else:\n",
        "      sent_hapax.append(w.lower())\n",
        "  corpus_hapax.append(sent_hapax)\n",
        "\n",
        "#Creando el diccionario con las palabras indexadas\n",
        "vocab = defaultdict()\n",
        "vocab.default_factory = lambda: len(vocab)\n",
        "voc_index = [[vocab[word] for word in line] for line in types]\n",
        "\n",
        "\n",
        "print(corpus_hapax[:5])\n",
        "print(voc_index[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['<bos>', '<oov>', 'a', 'trabaj', 'y', 'me', 'peg', 'me', '<oov>', 'con', '<oov>', '<eos>'], ['<bos>', 'mis', 'patron', 'me', 'peg', 'porqu', 'no', 'me', 'quer', 'apur', 'porqu', 'era', 'floj', '<eos>'], ['<bos>', 'por', 'eso', 'me', 'hab', 'peg', '<eos>'], ['<bos>', 'cuand', 'me', 'peg', 'ya', 'entonc', 'me', 'quit', '<eos>'], ['<bos>', 'pues', 'entonc', 'no', 'quis', 'trabaj', '<eos>']]\n",
            "[[0, 1, 2, 3, 4, 5, 6, 5, 7, 8, 9, 10], [0, 11, 12, 5, 6, 13, 14, 5, 15, 16, 13, 17, 18, 10], [0, 19, 20, 5, 21, 6, 10], [0, 22, 5, 6, 23, 24, 5, 25, 10], [0, 26, 24, 14, 27, 3, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9vCogsVPwYP"
      },
      "source": [
        "3. __Obtener los bigramas que aparecen en el texto.__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tXHsddd1PC5"
      },
      "source": [
        "Para esta parte, se usarán algunas partes del código del profesor Victor Mijangos, alojado en [este enlace](https://github.com/VMijangos/Curso-Procesamiento-de-Lenguaje-Natural/blob/master/Notebooks/09b%20Language_model_bigram_big.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxRQlepJP4lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d980dc8-d944-4ee1-ade2-4196b244d36f"
      },
      "source": [
        "#Se crean los bigramas\n",
        "bigrams = list(chain(*[zip(word,word[1:]) for word in voc_index]))\n",
        "\n",
        "#Se obtiene la frecuencia de cada bigrama\n",
        "frecBigrams = Counter(bigrams)\n",
        "\n",
        "#Tamaño del vocabulario\n",
        "N = len(voc_index)\n",
        "\n",
        "print('Tamaño del vocabulario:', N)\n",
        "print(\"bigramas: \", len(bigrams))\n",
        "print(bigrams[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño del vocabulario: 1075\n",
            "bigramas:  9874\n",
            "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 5), (5, 7), (7, 8), (8, 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dD4tD74P49B"
      },
      "source": [
        "4. __Entrenar con los bigramas la red neuronal y obtener los valores para los hiperparámetros. Tomar de 100 a 300 unidades para la capa oculta.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co8I6dVZLimv"
      },
      "source": [
        "Se realizará la importación de algunas bibliotecas no usadas hasta ahora para que los métodos de la clase propuesta funcionen. correctamente. Además se separan los bigramas (Que es lo que se usa para la red) en conjunto para entrenamiento y conjunto para pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxEYbfTxZIRi",
        "outputId": "83e746d5-235b-48e5-d17f-c9c34176008c"
      },
      "source": [
        "#Split en corpus train y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#El 0.3 denota el tamaño de la prueba, en este caso 30% del conjunto\n",
        "bigrams, bigrams_test = train_test_split(bigrams, test_size=0.3)\n",
        "print(\"Entrenamiento: \",len(bigrams))\n",
        "print(\"Pruebas: \",len(bigrams_test))\n",
        "print(bigrams[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrenamiento:  6911\n",
            "Pruebas:  2963\n",
            "[(394, 29), (31, 32), (326, 465), (26, 750), (39, 328)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl7jXYizHUGB"
      },
      "source": [
        "Utilizaremos una clase del modelo de Bengio, tomaremos la celda 17 del [código](https://github.com/penserbjorne/clase-pln-2020-2/blob/master/02_practica/practica_2.ipynb) donde está definida la clase a utilizar: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wroagpWQD4o"
      },
      "source": [
        "class Bengio:\n",
        "  # Constructor del objeto\n",
        "  def __init__(self, bigrams, T, d, m, n, N):\n",
        "    self.bigrams = bigrams\n",
        "    self.T = T    # Numero de iteraciones\n",
        "    self.d = d    # Dimension de los embeddings\n",
        "    self.m = m    # Numero de unidades en la capa oculta\n",
        "    self.n = n    # Rango de aprendizaje\n",
        "    self.N = N    # Tamaño del vocabulario\n",
        "\n",
        "  def initialize_params(self):\n",
        "    self.C = np.random.random((self.d, self.N))/np.sqrt(self.N)\n",
        "    self.W = np.random.random((self.m, self.d))/np.sqrt(self.d)\n",
        "    self.b = np.random.random(self.m)\n",
        "    self.U = np.random.random((self.N, self.m))/np.sqrt(self.m)\n",
        "    self.c = np.random.random(self.N)\n",
        "    self.R = []\n",
        "    self.R_it = 0\n",
        "\n",
        "  def forward(self, i_x):\n",
        "    c_i = self.C[:,i_x]\n",
        "    if np.size(np.dot(self.W, c_i)) == np.size(self.b): \n",
        "      h_i = np.tanh(np.dot(self.W, c_i) + self.b)\n",
        "    else:\n",
        "      h_i = np.tanh(np.dot(self.W, c_i))\n",
        "    a_i = np.dot(self.U, h_i) + self.c\n",
        "    e_a = np.exp(a_i - a_i.max())\n",
        "    p_wk_wi = e_a / e_a.sum()\n",
        "    return (p_wk_wi, h_i)\n",
        "\n",
        "  def risk(self, p_wk_wi, i_y):\n",
        "    self.R_it -= np.log(p_wk_wi[i_y].sum())\n",
        "\n",
        "  def saveRisk(self):\n",
        "    self.R.append(self.R_it)\n",
        "\n",
        "  def getRisk(self):\n",
        "    return self.R\n",
        "\n",
        "  def backward(self, i_y, p_wk_wi, h_i):\n",
        "    d_out = np.array(p_wk_wi, copy=True) \n",
        "    d_out[i_y] -= 1\n",
        "    d_h = (1 - (h_i*h_i)) * np.dot(d_out.T, self.U)\n",
        "    d_c = np.dot(d_h.T, self.W)\n",
        "    return (d_out, d_h, d_c)\n",
        "\n",
        "\n",
        "  def updateWeights(self, d_out, h_i, d_h, d_c, i_x):\n",
        "    self.U -= self.n * np.outer(d_out, h_i)\n",
        "    self.W -= self.n * np.outer(d_h, self.C[:, i_x])\n",
        "    self.c -= self.n * d_out\n",
        "    self.C[:, i_x] -=  self.n * d_c\n",
        "    self.b -= self.n * d_h\n",
        "\n",
        "#Único método modificado para que no muestre cada iteración\n",
        "  def train(self):\n",
        "    for it in range(0, self.T):\n",
        "      self.R_it = 0\n",
        "      for pair in self.bigrams:\n",
        "        i_x = pair[0]\n",
        "        i_y = pair[1] #Restando el símbolo inicial\n",
        "        p_wk_wi, h_i = self.forward(i_x)\n",
        "        self.risk(p_wk_wi, i_y)\n",
        "        d_out, d_h, d_c = self.backward(i_y, p_wk_wi, h_i)\n",
        "        self.updateWeights(d_out, h_i, d_h, d_c, i_x)\n",
        "      self.saveRisk()\n",
        "      print(\"Epoch: \", it, \"\\tEntropia cruzada: \", self.R_it)\n",
        "    print(\"Finished\")\n",
        "\n",
        "  def entropy_phrase(self, sentence):\n",
        "    entropy = 0\n",
        "    for pair in sentence:\n",
        "      i_x = pair[0]\n",
        "      i_y = pair[1]\n",
        "      p_wk_wi, h_i = self.forward(i_x)\n",
        "      entropy -= np.log(p_wk_wi[i_y].sum())\n",
        "    return entropy\n",
        "\n",
        "  def predict(self, i_x):\n",
        "    return np.argmax(self.forward(i_x)[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IXBPt7eITbd"
      },
      "source": [
        "Procedemos a crear el modelo con los parámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT5K-0mPIYSG",
        "outputId": "387b53cd-a65a-4379-84dc-f94452c76d33"
      },
      "source": [
        "# Creamos objeto del modelo y lo entrenamos\n",
        "# Los parámetros del constructor son:\n",
        "#   bigrams, iteraciones, embeddings, uni capa oculta,\n",
        "#   learning rate, tamaño del diccionario considerando bos y eos\n",
        "modelo = Bengio(bigrams, 5, 100, 300, 0.01, N)\n",
        "modelo.initialize_params()\n",
        "modelo.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 \tEntropia cruzada:  37820.48887319124\n",
            "Epoch:  1 \tEntropia cruzada:  35842.2188889669\n",
            "Epoch:  2 \tEntropia cruzada:  35025.37576888876\n",
            "Epoch:  3 \tEntropia cruzada:  34504.04947364847\n",
            "Epoch:  4 \tEntropia cruzada:  34016.860603208275\n",
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6ZaVx6UQEfH"
      },
      "source": [
        "5. __Evaluar el modelo (con Entropía y Perplejidad).__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gj0a0U3D2w0"
      },
      "source": [
        "Para tener una idea de que tan bueno es el modelo que estimamos, podemos utilizar la entropía cruzada empírica dada por la función:\r\n",
        "\r\n",
        "$$H_E(p) = -\\frac{1}{M} \\sum_{x_1,...,x_m}^N \\log p(x_1, ...x_m)$$\r\n",
        "En este caso, el modelo con menor entropía será aquel que mejor prediga una (o varias) cadenas no vistas. Por tanto, consideraremos que generaliza mejor.\r\n",
        "La perplejidad se define en base a esta entropía como $2^{H_E(p)}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1meJIVx7d6Ej"
      },
      "source": [
        "En nuestro caso para la entropía y perplejidad la clase tiene un método para recorrer los bigramas y calcular la entropía, que según como se dividió el conjunto solo le pasaremos como parámetro los bigramas de evaluación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6joxVPAud5Y_",
        "outputId": "dfdd37b5-1f37-463d-838e-087da9ba11f3"
      },
      "source": [
        "entropy_phrase = modelo.entropy_phrase(bigrams_test)\n",
        "\n",
        "entropy_phrase /= len(bigrams_test)\n",
        "\n",
        "print(\"Entropia del modelo evaluado: \", entropy_phrase)\n",
        "print(\"Perplejidad del modelo: \", 2**entropy_phrase)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropia del modelo evaluado:  5.059825328708344\n",
            "Perplejidad del modelo:  33.35486573166929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW1-vJn_QIJS"
      },
      "source": [
        "6. __Calcular la proabilidad de las siguientes oraciones:__\n",
        "+ Nos bañamos con agua caliente\n",
        "+ El animalito le olía la cabeza\n",
        "+ Pascuala ordeñaba las vacas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeF6KHPRj0Jy",
        "outputId": "bcbff63f-c742-4eb0-bacf-43ab5032ba29"
      },
      "source": [
        "# Creamos el corpus\n",
        "c_t = \"\"\"\n",
        "Nos bañamos con agua caliente\\n\n",
        "El animalito le olía la cabeza\\n\n",
        "Pascuala ordeñaba las vacas\\n\n",
        "\"\"\"\n",
        "c_tl = []\n",
        "for sent in c_t.split(\"\\n\"):\n",
        "  if sent != '':\n",
        "    c_tl.append(str.lower(re.sub(r\"[^\\w]\", \" \", sent)))\n",
        "\n",
        "print(c_tl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nos bañamos con agua caliente', 'el animalito le olía la cabeza', 'pascuala ordeñaba las vacas']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU-Xd51_jzL7"
      },
      "source": [
        "\n",
        "\n",
        "Stemmer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss7M9yPUktk6",
        "outputId": "88425514-2b5f-426c-a1a9-647c0c715935"
      },
      "source": [
        "stems = []\n",
        "for sent in c_tl:\n",
        "  stems.append([ps.stem(w) for w in sent.split(\" \") if w != \"\" and w != []])\n",
        "\n",
        "print(stems[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['nos', 'bañ', 'con', 'agu', 'calient'], ['el', 'animalit', 'le', 'oli', 'la', 'cabez'], ['pascual', 'ordeñ', 'las', 'vac']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4vXMZn5lLSn"
      },
      "source": [
        "Inserción de símbolos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_SCNu1nlQDI",
        "outputId": "a13a3730-35c0-4f63-e0b1-95b40cc7a8d5"
      },
      "source": [
        "for i,t in enumerate(stems):\n",
        "    t.insert(0,\"<BOS>\")\n",
        "    t.append(\"<EOS>\")\n",
        "   \n",
        "print(stems)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['<BOS>', 'nos', 'bañ', 'con', 'agu', 'calient', '<EOS>'], ['<BOS>', 'el', 'animalit', 'le', 'oli', 'la', 'cabez', '<EOS>'], ['<BOS>', 'pascual', 'ordeñ', 'las', 'vac', '<EOS>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ_7cOUinPKX",
        "outputId": "6b871e68-6e80-4561-d309-7b4c72217220"
      },
      "source": [
        "dic_wk_train = { w: idx for w,idx in vocab.items()}\n",
        "n_stems = []\n",
        "\n",
        "ids_tmp = []\n",
        "for word in line:\n",
        "    ids_tmp.append(dic_wk_train.get(word, dic_wk_train.get(\"<oov>\")))\n",
        "\n",
        "for line in stems:\n",
        "  for word in line:\n",
        "    n_stems.append(dic_wk_train.get(word, dic_wk_train.get(\"<oov>\")))\n",
        "\n",
        "n_bigrams = []\n",
        "n_bigrams = list(zip(n_stems, n_stems[1:])\n",
        "print(\"Bigrama\")\n",
        "print(n_bigrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bigrama\n",
            "[(0, 389), (389, 931), (931, 8), (8, 252), (252, None), (None, 10), (10, 0), (0, 73), (73, 180), (180, 102), (102, 1022), (1022, 58), (58, 338), (338, 10), (10, 0), (0, 589), (589, 862), (862, 44), (44, 248), (248, 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw910P1Tund9"
      },
      "source": [
        "Finalmente se calculan las probabilidades de las oraciones con los nuevos bigramas obtenidos de las oraciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0SaCuAcQaZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3944f616-0dd6-4adc-e91a-cab03e3add9a"
      },
      "source": [
        "# Tomandoel modelo de Bengio\n",
        "def prob_phrase_by_bengio(bigrams, model):\n",
        "    prob = 1\n",
        "    for bigram in bigrams:\n",
        "        i_x = bigram[0]\n",
        "        i_y = bigram[1]\n",
        "        #Manejando <oov>\n",
        "        if i_y is None: i_y, i_x = 0, 6\n",
        "        if i_x is None: i_y, i_x = 6, 0\n",
        "        prob *= model.forward(i_x)[0][i_y]\n",
        "        print(\"P: \", prob)\n",
        "    return prob\n",
        "\n",
        "min_i = 0\n",
        "max_i = 0\n",
        "\n",
        "for line in stems:\n",
        "    print(line)\n",
        "    max_i += len(line) - 1\n",
        "    prob = prob_phrase_by_bengio(n_bigrams[min_i:max_i], modelo)\n",
        "    print(\"Probabilidad de la frase: \", prob, \"\\n\")\n",
        "    min_i = max_i + 1\n",
        "    max_i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<BOS>', 'nos', 'bañ', 'con', 'agu', 'calient', '<EOS>']\n",
            "P:  0.004185980952449106\n",
            "P:  1.1812237843968197e-05\n",
            "P:  1.8393356447607428e-07\n",
            "P:  2.799147486525452e-10\n",
            "P:  2.0721316255810368e-15\n",
            "P:  2.211004206569331e-18\n",
            "Probabilidad de la frase:  2.211004206569331e-18 \n",
            "\n",
            "['<BOS>', 'el', 'animalit', 'le', 'oli', 'la', 'cabez', '<EOS>']\n",
            "P:  0.022161924835981804\n",
            "P:  3.0753858751538834e-05\n",
            "P:  1.3519321484237802e-07\n",
            "P:  8.577964221227131e-11\n",
            "P:  1.5015774517234578e-12\n",
            "P:  1.875402347986495e-14\n",
            "P:  7.286999054299841e-15\n",
            "Probabilidad de la frase:  7.286999054299841e-15 \n",
            "\n",
            "['<BOS>', 'pascual', 'ordeñ', 'las', 'vac', '<EOS>']\n",
            "P:  0.0002637520126092727\n",
            "P:  4.062444882898352e-08\n",
            "P:  2.2824474642211238e-10\n",
            "P:  1.5837247853817108e-12\n",
            "P:  5.510208528505273e-13\n",
            "Probabilidad de la frase:  5.510208528505273e-13 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNiD92zDJR2y"
      },
      "source": [
        "###**Referencias:**\r\n",
        "\r\n",
        "*   https://colab.research.google.com/drive/17p3ef9HyZ9N9rixGdr5yhLd_VGT0zpNk?usp=sharing\r\n",
        "*   https://github.com/VMijangos/Curso-Procesamiento-de-Lenguaje-Natural/blob/master/Notebooks/09b%20Language_model_bigram_big.ipynb\r\n",
        "*   https://github.com/penserbjorne/clase-pln-2020-2/blob/master/02_practica/practica_2.ipynb\r\n",
        "*   Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Jauvin.\r\n",
        "A neural probabilistic language model.\r\n",
        "Journal of machine learning research, 3(Feb):1137–1155, 2003.\r\n",
        "\r\n"
      ]
    }
  ]
}